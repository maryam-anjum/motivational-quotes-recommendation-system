{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load only necessary columns\n",
    "file_path = 'quotes.csv'\n",
    "df = pd.read_csv(file_path, usecols=['quote', 'author', 'category'])\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n",
    "\n",
    "# Sample only 100,000 rows if the dataset is larger\n",
    "if len(df) > 100000:\n",
    "    df = df.sample(n=100000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 179178 to 96474\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   quote     100000 non-null  object\n",
      " 1   author    99639 non-null   object\n",
      " 2   category  99983 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "quote         0\n",
      "author      361\n",
      "category     17\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df.dropna(subset=['quote', 'category'], inplace=True)\n",
    "df.dropna(subset=['author'], inplace=True)\n",
    "\n",
    "# Normalize text data\n",
    "df['quote'] = df['quote'].str.lower()\n",
    "df['author'] = df['author'].str.lower()\n",
    "df['category'] = df['category'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quote       0\n",
      "author      0\n",
      "category    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values in 'author' and 'category' columns with 'Unknown'\n",
    "df['author'].fillna('Unknown', inplace=True)\n",
    "df['category'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove any non-alphanumeric characters except spaces\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the 'quote' column\n",
    "df['quote'] = df['quote'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99327 entries, 179178 to 96474\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   quote     99327 non-null  object\n",
      " 1   author    99327 non-null  object\n",
      " 2   category  99327 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n",
      "                                                    quote  \\\n",
      "179178  the sting of her abandonment had not lessened ...   \n",
      "183253  everything that falls upon the eye is an appar...   \n",
      "84139   i dont hate republicans as individuals but i h...   \n",
      "272877                                think more not less   \n",
      "195518  some individuals have the courage to make it e...   \n",
      "\n",
      "                                                   author  \\\n",
      "179178            t.j. forrester, miracles, inc.: a novel   \n",
      "183253                  marilynn robinson in housekeeping   \n",
      "84139                                         howard dean   \n",
      "272877                                       jelani payne   \n",
      "195518  gino segrÃ¨, ordinary geniuses: max delbruck, g...   \n",
      "\n",
      "                                                 category  \n",
      "179178                      love, relationship, suffering  \n",
      "183253    grief, loss, memory, remembering-the-good, time  \n",
      "84139                               politics, republicans  \n",
      "272877                     critical-thinking, perspective  \n",
      "195518  comfortable, dream, inspirational, journey, jo...  \n"
     ]
    }
   ],
   "source": [
    "# Verify that the 'quote' column is not empty\n",
    "df = df[df['quote'].str.strip() != '']\n",
    "\n",
    "# Verify the final dataset\n",
    "print(df.info())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_file_path = 'cleaned_quotes.csv'\n",
    "df.to_csv(cleaned_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['quote'], df['category'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99327, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer with a max feature limit to manage memory usage\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "# Fit and transform the quotes\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['quote'])\n",
    "\n",
    "# Display the shape of the TF-IDF matrix\n",
    "print(tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99327, 58938)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize Count Vectorizer for categories\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda x: x.split(', '))\n",
    "# Fit and transform the categories\n",
    "category_matrix = count_vectorizer.fit_transform(df['category'])\n",
    "\n",
    "# Display the shape of the category matrix\n",
    "print(category_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import random\n",
    "\n",
    "def recommend_quotes_by_category(query_category, top_n=5, random_sample_size=None):\n",
    "    # Convert the query category into a tokenized format\n",
    "    query_vector = count_vectorizer.transform([query_category])\n",
    "    \n",
    "    # Calculate cosine similarity between the query and all categories\n",
    "    category_similarity = cosine_similarity(query_vector, category_matrix).flatten()\n",
    "    \n",
    "    # Get indices of top N similar categories\n",
    "    similar_category_indices = category_similarity.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # Collect the quotes corresponding to the top similar categories\n",
    "    top_similar_quotes = df.iloc[similar_category_indices]['quote'].tolist()\n",
    "    \n",
    "    if random_sample_size is not None:\n",
    "        # Randomly select quotes from the top similar quotes\n",
    "        if len(top_similar_quotes) > random_sample_size:\n",
    "            top_similar_quotes = random.sample(top_similar_quotes, random_sample_size)\n",
    "    \n",
    "    return top_similar_quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the happy and efficient people in this world are those who accept trouble as a normal detail of human life and resolve to capitalize it when it comes along\n",
      "a happy life is one which is in accordance with its own nature\n",
      "if you are happy dont analyse your happiness dont ask questions and dont even think about it just live it to the fullest\n",
      "make happy those who are near  and those who are far will come\n",
      "im so happy to be rich  im willing to take all the consequences\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query_category = 'happy'\n",
    "recommended_quotes = recommend_quotes_by_category(query_category, top_n=10, random_sample_size=5)\n",
    "for quote in recommended_quotes:\n",
    "    print(quote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (495350, 10000)\n",
      "Category matrix shape: (495350, 146505)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['category_matrix.joblib']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from tokenizer import tokenizer  # Import the tokenizer function\n",
    "\n",
    "# Load the dataframe\n",
    "df = pd.read_pickle('quotes_df.pkl')\n",
    "\n",
    "def recommend_quotes_by_category(query_category, top_n=5, random_sample_size=None):\n",
    "    query_vector = count_vectorizer.transform([query_category])\n",
    "    category_similarity = cosine_similarity(query_vector, category_matrix).flatten()\n",
    "    similar_category_indices = category_similarity.argsort()[-top_n:][::-1]\n",
    "    top_similar_quotes = df.iloc[similar_category_indices]['quote'].tolist()\n",
    "    random.shuffle(top_similar_quotes)  # Shuffle the quotes\n",
    "    if random_sample_size is not None:\n",
    "        if len(top_similar_quotes) > random_sample_size:\n",
    "            top_similar_quotes = random.sample(top_similar_quotes, random_sample_size)\n",
    "    return top_similar_quotes\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['quote'])\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Initialize Count Vectorizer with the named function\n",
    "count_vectorizer = CountVectorizer(tokenizer=tokenizer)\n",
    "category_matrix = count_vectorizer.fit_transform(df['category'])\n",
    "print(f\"Category matrix shape: {category_matrix.shape}\")\n",
    "\n",
    "# Save the vectorizers and matrices\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "joblib.dump(count_vectorizer, 'count_vectorizer.joblib')\n",
    "joblib.dump(tfidf_matrix, 'tfidf_matrix.joblib')\n",
    "joblib.dump(category_matrix, 'category_matrix.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
